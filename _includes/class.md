# CSE 704 - Applied Natural Language Processing and Computational Social Science

# Details

- Time: Wednesdays, 10:25-12:30 PM
- Location:  Zoom :(

- Office Hours: Virtual, by appointment

- Communication via email: **Please prefix all emails to me with [CSE702] in the subject so I can respond in a timely manner**.

# Overview 

This seminar course will focus on giving students a broad understanding of state-of-the-art methods in NLP and how they can be applied to address questions in the social sciences and/or humanities. Topics will also include other relevant areas of computational social science, broadly construed, including research on ethics, fairness, and power in applications of machine learning.

# Schedule

| Week | Date | Theme | Papers | Slack Channel |
| :---- | :-----: | :-----: | :--------- | :----------: |
|1 | February 3 | **Introduction - NLP&CSS**  | | #intro |
|2 | February 10 | **Examples 1** | - Abebe et al. (2020). *[Quantifying Community Characteristics of Maternal Mortality Using Social Media](https://www.cs.cornell.edu/~red/AbebeMaternalMortality.pdf)* <br> - Rajadesingan et al. (2019). *[Smart, Responsible, and Upper Caste Only: Measuring Caste Attitudes through Large-Scale Analysis of Matrimonial Profiles](https://ashwinrajadesingan.com/files/camera_ready_icwsm.pdf)* <br> -  Cranshaw et al. (2012). *[The Livehoods Project: Utilizing Social Media to Understand the Dynamics of a City]()*  | #css_examples_1 |
|3 | February 17 | **Examples 2** | - Jones et al. (2020). *[Behind the Mask: A Computational Study of Anonymous’ Presence on Twitter](https://ojs.aaai.org//index.php/ICWSM/article/view/7303/7157). <br> - Zhang and Danescu-Niculescu-Mizi. (2020). *[Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards](https://www.cs.cornell.edu/~cristian/Orientation_files/orientation-forwards-backwards.pdf)* <br> - Antoniak et al. (2019). *[Narrative Paths and Negotiation of Power in Birth Stories](https://dl.acm.org/doi/pdf/10.1145/3359190)* | #css_examples_2 |
|4 | February 24 |  **Data Collection** | - Marwick and boyd. (2011). *[I tweet honestly, I tweet passionately: Twitter users, context collapse, and the imagined audience](https://doi.org/10.1177/1461444810365313)* <br>  -   Ernala et al. (2019) *[Methodological gaps in predicting mental health states from social media: Triangulating diagnostic signals](http://www.munmund.net/pubs/CHI19_MethodGaps.pdf)* <br>  -  Irani and Silberman. (2015). *[Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk](https://escholarship.org/content/qt10c125z3/qt10c125z3.pdf])* <br> - Baumgartner et al. (2020) *[The pushshift reddit dataset](https://ojs.aaai.org/index.php/ICWSM/article/download/7347/7201/)* <br> - Pfeffer et al (2018). *[Tampering with Twitter’s sample API](https://link.springer.com/content/pdf/10.1140/epjds/s13688-018-0178-0.pdf)* <br> -   Tufekci (2014). *[Big Questions for Social Media Big Data: Representativeness, Validity and Other Methodological Pitfalls](https://arxiv.org/abs/1403.7400)* | #data |
|5 | March 3 | **Annotation** | -   Snow et al. (2008). *[Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks](http://www.aclweb.org/anthology/D08-1027)*   <br> - Geiger et al. (2020). *[Garbage In, Garbage Out? Do Machine Learning Application Papers in Social Computing Report Where Human-Labeled Training Data Comes From?](https://arxiv.org/abs/1912.08320)* <br> - Pavlick and Kwiatkowski. (2019). *[Inherent Disagreements in Human Textual Inferences](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00293)* <br> - Paun et al. (2018). *[Comparing Bayesian Models of Annotation](https://www.mitpressjournals.org/doi/pdfplus/10.1162/tacl_a_00040)*|#annotation| 
|6 | March 10 |  **Modern NLP 1** | - **<span style="color:blue">Read this one first::: </span>** Smith. (2019). *[Contextual Word Representations: A Contextual Introduction](http://arxiv.org/abs/1902.06006)* <br>  -  Pennington et al.(2014). *[Glove: Global vectors for word representation](http://www.aclweb.org/anthology/D14-1162)* <br> - Mikolov et al. (2013). [*Efficient estimation of word representations in vector space*](https://arxiv.org/pdf/1301.3781.pdf) <br> - Levy et al. (2015). *[Improving distributional similarity with lessons learned from word embeddings](https://www.transacl.org/ojs/index.php/tacl/article/view/570/124)* | #modernnlp_1|
|7 | March 17 |  **Modern NLP 2** | - Vaswani et al. (2017). *[Attention Is All You Need](https://arxiv.org/abs/1706.03762)* <br> -  Devlin et al. (2018). *[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)* <br>  -  Liu et al. (2019). *[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)*  <br> - de Vries et al. (2020). *[What's so special about BERT's layers? A closer look at the NLP pipeline in monolingual and multilingual models](https://arxiv.org/abs/2004.06499)* | #modernnlp_2|
|8 | March 24 |   **Topic Models** | - Blei. (2012) *[Probabilistic topic models](https://oar.princeton.edu/bitstream/88435/pr1bv3w/1/OA_IntroductionProbabilisticTopicModels.pdf)* <br>  - Bamman et al. (2014). *[A bayesian mixed effects model of literary character](http://www.aclweb.org/anthology/P14-1035)*  <br> - Rudolph and Blei. (2018). [Dynamic Embeddings for Language Evolution](https://pdfs.semanticscholar.org/c4e7/2c764266d85ce0ade71fa812bda43bdd6437.pdf) <br> - Demszky et al. (2019). *[Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings](https://arxiv.org/abs/1904.01596)* <br> | #topicmodeling|
|9| March 31 |   **Sentiment** | - Hutto & Gilbert (2014). [*Vader: A parsimonious rule-based model for sentiment analysis of social media text*](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8109/8122) <br> - Felbo et al. (2017). [*Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm*](http://www.aclweb.org/anthology/D17-1169) <br> - Xu et al. (2019). *[BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis](https://www.aclweb.org/anthology/N19-1242.pdf)* | #sentiment|
|10| April 7 |    **Stance** | - Sen et al. (2020). *[On the Reliability and Validity of Detecting Approval of Political Actors in Tweets](https://www.aclweb.org/anthology/2020.emnlp-main.110.pdf)* <br> - Aldayel and Magdy (2019). *[Your Stance is Exposed! Analysing Possible Factors for Stance Detection on Social Media](https://arxiv.org/pdf/1908.03146.pdf)* <br> - Darwish et al. (2020). *[Unsupervised User Stance Detection on Twitter](https://ojs.aaai.org/index.php/ICWSM/article/view/7286)* | #stance|
|11| April 14 | **Bias NLP 1** | -  Bolukbasi et al. (2016). *[Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf)* <br>  -   De-Arteaga et al. (2019). *[Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting](https://arxiv.org/pdf/1901.09451.pdf)* <br>  -  Ethayarajh et al. (2019). *[Understanding Undesirable Word Embedding Associations](https://www.aclweb.org/anthology/P19-1166/)* <br>  -   Gonen and Goldberg. (2019). *[Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them](https://arxiv.org/abs/1903.03862)* | #bias1|
|12| April 21 | **Bias in NLP 2** | - Bender et al. (2021). *[On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf)* <br> - Rudinger et al. (2018). *[Gender Bias in Coreference Resolution](https://arxiv.org/abs/1804.09301)*. <br> - Blodgett et al. (2020). *[Language (Technology) is Power: A Critical Survey of" Bias" in NLP](https://arxiv.org/pdf/2005.14050.pdf)*. <br> -  Zhao et al. (2019). *[Gender Bias in Contextualized Word Embeddings](https://arxiv.org/abs/1904.03310)*   | #bias2 |
|13| April 28 |  **Syncing w/ Qualitative Research** | - Eads et al. (2020). *[Separating the wheat from the chaff: A topic- and keyword-based procedure for identifying research-relevant text]()*. <br> - Muller et al. (2016). *[Machine Learning and Grounded Theory Method: Convergence, Divergence, and Combination](https://cpb-us-e1.wpmucdn.com/blogs.cornell.edu/dist/c/3483/files/2017/02/Muller2016-Machine-2bp3h65.pdf)* <br> - Patton et al. (2020). *[Contextual Analysis of Social Media: The Promise and Challenge of Eliciting Context in Social Media Posts with Natural Language Processing](https://safelab.socialwork.columbia.edu/sites/default/files/2020-03/CASM.pdf)* | #qualitative |
|14| May 5 |  **Bias beyond NLP** | -  Obermeyer et al. (2019). *[Dissecting racial bias in an algorithm used to manage the health of populations](https://science.sciencemag.org/content/366/6464/447)* <br>  -   Chouldechova. (2017). *[Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments](https://www.liebertpub.com/doi/abs/10.1089/big.2016.0047)* <br>  -  Ensign et al. (2017). *[Runaway Feedback Loops in Predictive Policing](http://arxiv.org/abs/1706.09847)* <br>  -   Bokányi & Hannák (2019). *[Ride-share matching algorithms generate income inequality](http://arxiv.org/abs/1905.12535)* <br>  | #big_bias |
| | May 15 | **FINAL PROJECTS DUE** | |#project|



# Prerequisites

It is assumed that students have some background in machine learning. Also, although not required, this course will likely be most interesting to those with an interest in the social sciences and/or humanities.

# Course Credits

You can take this seminar for either 1 credit or 3 credits. With 1 credit, your responsibility is to read papers, write and respond to critiques on the course slack channel, and present two papers to the class. With 3 credits, you will also design and carry out a research project that will be presented in a poster session at the end of the semester

# Grading

The class will be (and is required to be) graded pass/fail.

## Attendance Policy 

**Missing more than three scheduled course meetings will result in a failing grade**. The only condition under which the student can still pass the course if they miss more than three scheduled meetings is if **all but one** absence is documented with the instructor and due to the following reasons (from [UB's official policy](https://catalog.buffalo.edu/policies/attendance.html)):
- military obligations
- religious observances
- illness documented by a physician or other appropriate health care professional
- conflicts with university-sanctioned activities documented by an appropriate university administrator
- public emergencies
- documented personal or family emergencies

**Consistently being more than 5 minutes late to class will result in me counting you as absent**. Specifically, every three times that you are more than 5 minutes late will be counted as a missed class. **There are no exceptions to this policy**. 

Please note that I *do not need a reason for missing class if you miss three or less*. That is, as long as you don't miss more than three classes, you can be absent for any reason. Note, however, that you will not receive credit for attendance on those days **unless documentation is provided for one of the reasons above**.


## Readings, Participation, and Presentations

Each week, [readings](#readings) are graded on a seven point scale:
- A [one to two paragraph response on Slack](#reading-responses-on-slack) to at least three readings (**1 point per reading**)
- Two useful [comments](#comments-on-responses-on-slack) on someone else's response (**.5 points per comment, up to 1 point, or two comments**)
- Attendence at and [active participation](#class-participation) in class, which includes the ability to discuss up to 3 papers for that week (**3 points**)

Important notes on weekly graded assignments:
- **There are 12 weeks of reading assignments. I will grade out of a possible of 10 weeks for each sub-assignment. So responses are graded out of 30 points, comments out of 10, and attendence/participation out of 30.** Note, then, that the grading of responses is **separate** from 

In addition, you will present two papers to the class. These presentations will be graded on an additional 15-points:
- 12 minute presentation of the paper (guidelines below; **10 points**)
- Taking part in leading the discussion of the paper in class (**5 points**)

Students taking the course for 1 credit must do the following to pass the course:
- Get at least **85 points**
- Actively participate in class discussions
- Present two papers

For students taking the course for three credits, an additional **80 points** are allocated to the [project](#project).

Students taking the course for 3 credits must also **get at least 60 points on the project** in order to pass the course, and **must submit something at every established deadline**.


# Reading and paper presentation details

## Readings 

We will use the "three pass" reading system described [here](https://cse.buffalo.edu/~stevko/courses/cse704/fall10/papers/p83-keshav.pdf). For your three responses to papers, you should use a "second pass" style of reading. For any other papers assigned (i.e. if there are more than three readings for a given week), use a "first pass" style for papers you did not write responses to.  For your presentations, you should be taking a "third pass" approach to reading the articles.  Keep in mind these are loose guidelines, not strict characterizations of how you should read the paper.

## Class participation

Students are expected to actively participate in discussion of all papers for which they give a response.  Students should expect to be called upon to discuss the responses they give on Slack during class and to address other potential discussion topics.

## Reading Responses on Slack

All responses to readings must be put onto Slack by **Tuesday at 8:00PM**, onto the slack channel for that week's readings.  Responses submitted after this time or to a different channel will not be accepted.

Responses to readings should have two paragraphs  **Before these two paragraphs, state the paper you are responding to in bold.  See the #intro channel for example responses**.
The first paragraph might choose to address some of the following questions, but should not feel inclined to simply answer only or all these questions:

- What is the main point of the paper?
- What novel technical insights does the paper have, if any?
- What novel social science insights does the paper have, if any?
- What is the biggest strength of the paper, if any?
- What is the biggest weakness of the paper, if any?

The second paragraph might consider some of the following questions:

- Does this paper help you think in a new way about a problem you're working on?
- Is there a part of the paper you found particularly confusing that you'd like help understanding?
- How does this paper link to some of the other papers we discussed this week?

This second paragraph will serve as the basis for discussion during the class.

## Comments on Responses on Slack

All comments must be put onto Slack by **Tuesday at 11:59PM**, replying to another response or comment from someone else on the slack channel for that week's readings.  Comments submitted after this time or to a different channel will not be accepted.

**Further, all comments should be civil.  Verbal abuse or intimidation, or attempts to make others "feel dumb" or that are offensive in any way will not be tolerated.  If you believe your comment might fall into this space, please me an email before posting it so we can discuss this.  Any violation of this practice will be treated as a violation of the university's policy for Academic Integrity**

## Paper presentations

Paper presentations are expected to be 12 minutes long (give or take a minute or two).  Slides are not due beforehand, but I am happy to provide feedback if the slides are sent before Tuesday.  I will also ask that slides are sent to me after the presentation in PDF format in order to post them to the website. 

The presentation should cover the following, although you may choose to spend more or less time on particular parts (i.e. you may want to spend a lot of time on the methodology if its a methods paper, or the interesting results if it is an application paper):

- A summary slide - what was the main point of the paper, the main methods and data used, and the main conclusion
- Detailed summary of the paper
	- What were the main research questions or hypotheses that the paper was looking at? Or, what was the main technical challenge the paper was seeking to address?
	- Why is (or isn't) this an important problem? I.e. why is (or isn't) this paper interesting and important?
	- How did this paper go about answering these research questions?
		- Details on the data, including potential biases within it
		- Details on the methodology - you should give enough detail here that someone who has not read the paper at all can grasp all steps of the methodology
	- What are the main results of the paper, in terms of the research questions posed?
	
- Your personal take on the paper
	- Would you recommend this paper to others? Why or why not?
	- What are the key weaknesses of this paper?
	- What are the key strengths of this paper?
	- If this is a methods paper, where else do you think this method could be useful; i.e. what other datasets or kinds of data? Would the method need to be changed in order to do so?
	- If this is an application paper, what other methods do you think might have been applicable to the problem? Would using a different method have been better or lead to different conclusions? If so, how/why?
	- Can you think of other related papers beyond the ones the authors reference, e.g. papers that followed after this one? nAre there any related papers you think people should read if they are interested in this topic?
	
- A summary of the slack discussion around this paper.  What were the most popular responses? Were there any things people didn't understand? Have you clarified them?
- What would be useful for the class to discuss for this paper? Give at least three points for further discussion.

Additionally, the first slide should contain:
- Title of the paper
- Paper authors
- Full citation of the paper (APA format or similar is fine)
- Your name and the date of the presentation.

# Project Details

The final project in the class will involve running through the standard NLP+CSS pipeline to analyze either stance (using the method from the [Darwish et al paper](https://ojs.aaai.org/index.php/ICWSM/article/view/7286) or sentiment (using the method from the  [Felbo et al. paper](http://www.aclweb.org/anthology/D17-1169)). See [Model Building](#model-building) below for details on how the models will be implemented. 
 1. Select a question
 2. Collect some (social media) data
 3. Annotate some of that data
 4. Apply a machine learning model to the data
 5. Analyze the quality of model predictions
 6. Use the model to draw some substantitive conclusions. 
 
 This project is to be performed in teams of *2* students, although as you will see, there will be opportunities for larger collaboration. If there is an odd number of students, I will allow one group of three students.
 
There will be a series of deadlines for the projects throughout the semester; namely, I will make sure that you have completed each of these six steps at various points throughout the semester. For these deadlines:

- All submissions should be sent to me **via Slack** (except for the in person meeting and the presentation, obviously).
- All submissions are due by 11:59PM on the date listed
- We will have follow-up meetings for some teams, if so, those will be during class time
- All reports should be formatted should be submitted as a PDF with a specific formatting: you can use either the [AAAI overleaf template](https://www.overleaf.com/latex/templates/aaai-press-latex-template/jymjdgdpdmxp) or use the Word template in [this Google Doc](https://drive.google.com/file/d/1rox9tHLZkG6r_sxcG6rdRi-51ik8VkaI/view?usp=sharing). Either way, we will use Overleaf or Google Docs!

## Project Deadlines 
- **February 10th** - Slack me with the names of the members of your team, and your team name (5 points)
- **February 17th** - Meet with Kenny (this will be during class time) to finalize the research question (5)
- **March 3rd** - [Data Collection Report](#data-collection-reports) (15)
- **March 17th** - [Annotation Report](#annotation-reports) (15)
- **April 21nd** - [Almost Final Report](#almost-final-reports) (25)
- **May 9th** - [Optional poster presentations](#poster-presentations) (+10 Bonus)
- **May 14th** - [Final project reports due](#final-reports) (35)


## Model Building

This class is *not* focused on how to build machine learning models. Because of that, I have explicitly chosen models that either are available on github ([HuggingFace implementation](https://github.com/huggingface/torchMoji) or the [original implementation](https://github.com/bfelbo/DeepMoji)) or that are fairly straightforward to implement using existing tools (with, also, the help of existing code I will provide). 

As such, you are **encouraged** to a) reuse existing code from the web for the modeling process and b) to consult with each other within the class on implemenations. **Ideally**, we would have, as a class, a single implementation of these models (if re-implementation is needed) that we could *collectively publish to GitHub*.

## Data Collection Reports

The data collection report should be at most 2 pages long (using the specified format). It should include:
- A description of your research question
- Details on the source of your data (e.g. the Twitter API)
- (Brief) technical details on how you are collecting the data
- The current status of your collection (e.g. how many tweets/posts, is it on-going)


## Annotation Reports

The annotation report should be at most 3 pages long (using the specified format). It should include:

- A link to your data collection report
- A description of how many posts you plan to annotate, who you will have annotate them, and how long you expect the annotation task to take
- A description of how you will evaluate the quality of the annotations
- A description of what you will do if the annotations are of low quality (e.g. redo, get more annotations, change the task, etc.)

## Almost Final Reports

The Almost Final Report should be at most 4 pages long. It should include: 

- A description of your research question
- A description of the final dataset you have collected
- The results of your annotation task
- Evidence that you have built and applied the model you have selected to your data. 

## Final Reports

The format of your final report can be loosely aligned with that of the typical research papers we have read, i.e. it will likely have the at least the following sections:

- Introduction - This section should explain the objective of your project - what were you trying to do?  It should also explain why that objective is important - why do you want to carry out this research, how would it move our understanding of the social world forward?

- Background Section - This section will provide a literature review that would be appropriate for a conference paper, and should include works covered in class that are relevant to your research question. You should also include at least 1 reference to your specific project; Kenny will help you identify that!

- Data description - How did you collect this data? What are the strengths and weaknesses of it? How does the data that you have to analyze compare to the data in the paper you're replicating?

- Methodology - What was the approach you took to analyze the data. How did this approach compare to the original paper? Was it the same?

- Annotation and Model Results - How did your annotation process go? What worked, what didn't? Be honest here, no need to skim over details. If things failed miserably, so be it, but I want to hear about it! Then, look at the results of your model!

- Results – Provide the results of your analysis, and compare them to the results of the original paper.  If the replication did not succeed, try to explain why not. Were you lacking key information from the original authors? Were you unable to obtain the same data? If the replication did succeed, try to explain the limitations of your replication: would it work on other data? Does it rely on the method being implemented in exactly the same way as the original authors did?

- Conclusion - What did you learn - about computational social science, replication, and the original paper? What other important things did you glean from your analyses that may not have been noted in the original paper (especially if you carried out an extension of it)?

## Poster Presentations

All teams will have the option to present posters at the [CSE Demo Day](https://odin.cse.buffalo.edu/demoday). You will have worked hard on this project, and I want you to show that work off! But, this is a bonus, and is hence optional and those who participate will be awarded bonus points. 

# In progress list of miscellaneous related resources

## Syllabi for a subset of related courses

- [John Mclevey: Computational Social Science](http://www.johnmclevey.com/475/)
- [Jacob Eisenstein: Computational Social Science course](https://github.com/jacobeisenstein/gt-css-class)
- [Many folks: Computational Social Science Summer School](https://compsocialscience.github.io/summer-institute/2018/boulder/)
- [Katrin Tiidenberg: Social Media and Society](http://kkatot.tumblr.com/post/177696913112/syllabus-social-media-and-society-2018)
- [Pablo Barbera: Measurement Models and Statistical Computing](http://pablobarbera.com/POIR613/index.html)
- [Brendan O'Connor: Introduction to NLP](https://people.cs.umass.edu/~brenocon/inlp2016/)
- [Brandon Stewart: Text as Data](https://scholar.princeton.edu/sites/default/files/bstewart/files/textsyllabus2016.pdf)
- [Matt Salganik: Computational Social Science](http://www.princeton.edu/~mjs3/soc596_f2016/)
- [Philip Resnik: Computational Social Science](http://users.umiacs.umd.edu/~resnik/ling848_fa2013/syllabus.html)
- [Chenhao Tan: Reading group on social aspects of language](https://chenhaot.com/courses/reading-group-on-social-aspects-of-language.html)
- [Chenhao Tan: Human Centered Maching Learning (S20)](https://github.com/BoulderDS/human-centered-machine-learning)
- [Justin Grimmer: Text as Data Syllabus](http://stanford.edu/~jgrimmer/Text14/textsyll.pdf)
- [Chris Bail: Data Science and Society](https://dssoc.github.io/schedule/)

## Books:
- [Dirk Hovy's NLP Book](https://www.cambridge.org/core/elements/text-analysis-in-python-for-social-scientists/BFAB0A3604C7E29F6198EA2F7941DFF3)
- [Bit by bit: Social Research in the Digital Age](https://www.bitbybitbook.com/)
- [Natural Langauge Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)
- [Networks, Crowds, and Markets](http://www.cs.cornell.edu/home/kleinber/networks-book/)
- [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf)
- [(Technical) Book on fairness in ML by Barocas, Hardt and Narayanan](https://fairmlbook.org/)
- [(Non-technical) book on “Ethical Algorithms” by Kearns and Roth](https://global.oup.com/academic/product/the-ethical-algorithm-9780190948207?cc=us&lang=en&)

## Resource Lists:

- [The Best Machine Learning Resources](https://medium.com/machine-learning-for-humans/how-to-learn-machine-learning-24d53bb64aa1)
- [Some fast.ai deep learning courses](https://www.fast.ai/)
- [The 2019 AI Now Report](https://ainowinstitute.org/AI_Now_2019_Report.pdf)
